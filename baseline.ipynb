{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils import preprocess, train_utils\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import tensorboardX\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path_to_base = pathlib.Path('/opt/data/anuj/other/quora/processed')\n",
    "df_train = pd.read_csv(str(path_to_base / 'train.csv'))\n",
    "df_val = pd.read_csv(str(path_to_base / 'val.csv'))\n",
    "df_test = pd.read_csv(str(path_to_base / 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('/opt/data/anuj/other/quora/glove.840B.300d/pickle.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataloader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DEVICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "dataset_train = preprocess.QuoraDataset(df_train, word_vectors=embeddings, preprocessor=preprocess.preprocessor)\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n",
    "\n",
    "# Val\n",
    "dataset_val = preprocess.QuoraDataset(df_val, word_vectors=embeddings, preprocessor=preprocess.preprocessor)\n",
    "dataloader_val = DataLoader(dataset=dataset_val, batch_size=BATCH_SIZE, pin_memory=True, shuffle=True)\n",
    "\n",
    "print(len(dataset_train), len(dataloader_train))\n",
    "print(len(dataset_val), len(dataloader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataloader_train)\n",
    "next(it)['final_sentence1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bincounts = df_train.target.value_counts().values\n",
    "bincounts = 1. / bincounts\n",
    "bincounts = bincounts / bincounts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bincounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_baseline import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM().cuda(device=DEVICE)\n",
    "\n",
    "n_params = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad: n_params += np.prod(param.size())\n",
    "\n",
    "print(f'Model had {n_params} params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optim and loss\n",
    "weights = torch.from_numpy(bincounts.astype(np.float32)).cuda(device=DEVICE)\n",
    "loss_func = torch.nn.NLLLoss(weight=weights).cuda(device=DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'quora-insencere-lstm-1.1'\n",
    "\n",
    "model_dir = '/opt/weights/insincere/{}'.format(model_str)\n",
    "log_dir = '/home/anuj/code/tensorboard-logs/{}'.format(model_str)\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=False)  # MEANT TO FAIL IF IT ALREADY EXISTS\n",
    "writer = tensorboardX.SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_utils.train(\n",
    "    model=model, dataloader_train=dataloader_train, dataloader_val=dataloader_val,\n",
    "    loss_func=loss_func, optimizer=optimizer, device=DEVICE, writer=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
