{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings in Gensim Word2Vec format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    glove_file = datapath(str(path_to_embeddings))\n",
    "    tmp_file = datapath('/opt/data/anuj/other/quora/glove.840B.300d/word2vec_format.txt')\n",
    "    # call glove2word2vec script\n",
    "    from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "    # NOTE: this part takes 10-11 mintutes on a fast computer!\n",
    "    embeddings = KeyedVectors.load_word2vec_format('/opt/data/anuj/other/quora/glove.840B.300d/word2vec_format.txt')\n",
    "\n",
    "    with open('/opt/data/anuj/other/quora/glove.840B.300d/pickle.pkl', 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format('/opt/data/anuj/other/quora/glove.840B.300d/word2vec_format.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = pathlib.Path('/opt/data/anuj/other/quora/train.csv')\n",
    "path_to_test = pathlib.Path('/opt/data/anuj/other/quora/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train_all = pd.read_csv(str(path_to_train))\n",
    "df_heldout = pd.read_csv(str(path_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all[\"question_text\"] = df_train_all[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(clean_text(x)))\n",
    "sentences = df_train_all[\"question_text\"].apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov = check_coverage(vocab, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train into train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random split\n",
    "n = df_train_all.shape[0]\n",
    "n_train = int(0.7 * n)\n",
    "n_val = int(0.2 * n)\n",
    "\n",
    "df_train_all = df_train_all.sample(frac=1, axis=0, random_state=555)\n",
    "assert df_train_all.shape[0] == n\n",
    "\n",
    "df_train = df_train_all.iloc[: n_train]\n",
    "df_val = df_train_all.iloc[n_train: n_train + n_val]\n",
    "df_test = df_train_all.iloc[n_train + n_val:]\n",
    "assert df_train.shape[0] + df_val.shape[0] + df_test.shape[0] == n\n",
    "\n",
    "path_to_base = path_to_train.parent / 'processed'\n",
    "df_train.to_csv(str(path_to_base / 'train.csv'), index=False)\n",
    "df_val.to_csv(str(path_to_base / 'val.csv'), index=False)\n",
    "df_test.to_csv(str(path_to_base / 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(str(path_to_base / 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
